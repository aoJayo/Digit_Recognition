{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://www.youtube.com/watch?v=01sAkU_NvOY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The volume control method was used implemented to trigger the writing mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import tkinter as tk\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "from collections import deque\n",
    "\n",
    "model = load_model('Assesment3AAImodelJohnsonPaku.h5')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "wcam,hcam =1200, 480\n",
    "cap.set(3,wcam)\n",
    "cap.set(4,hcam)\n",
    "red_low = np.array([0, 0, 255])\n",
    "red_high = np.array([0, 0, 255])\n",
    "test_image = 0\n",
    "\n",
    "def image_conversion(test):\n",
    "    test = cv2.resize(test, (28, 28))\n",
    "    test = test.reshape((28, 28, 1))\n",
    "#     test = np.array([test])\n",
    "    data = np.array(test)\n",
    "    data = data/255.0 # for range b/w 0-1\n",
    "    data = data.reshape(1, 28, 28, 1).astype('float32')\n",
    "#     plt.imshow(data)\n",
    "    return data\n",
    "    \n",
    "\n",
    "def DrawContours(frame, points):\n",
    "    for i in range(1, len(points)):\n",
    "        if points[i - 1] is None or points[i] is None:\n",
    "            continue\n",
    "        cv2.line(frame, points[i-1], points[i], (0, 0, 255), 47)\n",
    "\n",
    "drawingModule = mp.solutions.drawing_utils\n",
    "handsModule = mp.solutions.hands\n",
    "pTime = 0\n",
    "digitlist = []\n",
    "points = deque(maxlen=480)\n",
    "detector = mp.solutions.hands\n",
    "text=''\n",
    "\n",
    "with handsModule.Hands(static_image_mode=False, min_detection_confidence=0.7, min_tracking_confidence=0.5, max_num_hands=2) as hands:    \n",
    "    while (True):\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "         ### FPS frame rate\n",
    "        cTime = time.time()\n",
    "        fps = 1/(cTime-pTime)\n",
    "        pTime = cTime\n",
    "        #cv2.putText(frame,f'FPS: {int(fps)}',(40,50),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,0),3)\n",
    "        cv2.putText(frame,'press c to clear and q to quit',(40,50),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,0),3)\n",
    "        #image = cv2.circle(frame, (cx,cy), 10, (0, 0, 255), -1)\n",
    "        results = hands.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        imageHeight, imageWidth, _ = frame.shape\n",
    "        \n",
    "        # draw contours on the frames\n",
    "        DrawContours(frame, points)\n",
    "           \n",
    "        # Draw and sample hand and Hand tracing    \n",
    "        if results.multi_hand_landmarks != None:\n",
    "            \n",
    "            cv2.putText(frame, \"Prediction is : \" + str(text), (100,100), cv2.FONT_HERSHEY_COMPLEX, 0.7, (255,0,0), 2,cv2.LINE_AA) \n",
    "\n",
    "            for handLandmarks in results.multi_hand_landmarks:\n",
    "                #drawingModule.draw_landmarks(frame, handLandmarks, handsModule.HAND_CONNECTIONS)\n",
    "                #get normalized position of index and thumb\n",
    "                thumb, index, middle, ring, pinky = handLandmarks.landmark[4],handLandmarks.landmark[8], handLandmarks.landmark[12],handLandmarks.landmark[16],handLandmarks.landmark[20]\n",
    "                index_k, middle_k, ring_k, pinky_k = handLandmarks.landmark[5],handLandmarks.landmark[9],handLandmarks.landmark[13],handLandmarks.landmark[17]\n",
    "                \n",
    "                # normalize landmark positions\n",
    "                findex = drawingModule._normalized_to_pixel_coordinates(index.x, index.y, imageWidth, imageHeight)\n",
    "                fthumb = drawingModule._normalized_to_pixel_coordinates(thumb.x, thumb.y, imageWidth, imageHeight)\n",
    "#                 fmiddle = drawingModule._normalized_to_pixel_coordinates(middle.x, middle.y, imageWidth, imageHeight)\n",
    "#                 fring = drawingModule._normalized_to_pixel_coordinates(ring.x, ring.y, imageWidth, imageHeight)\n",
    "#                 fpinky = drawingModule._normalized_to_pixel_coordinates(pinky.x, pinky.y, imageWidth, imageHeight)\n",
    "#                 findex_k = drawingModule._normalized_to_pixel_coordinates(index_k.x, index_k.y, imageWidth, imageHeight)\n",
    "#                 fmiddle_k = drawingModule._normalized_to_pixel_coordinates(middle_k.x, middle_k.y, imageWidth, imageHeight)\n",
    "#                 fring_k = drawingModule._normalized_to_pixel_coordinates(ring_k.x, ring_k.y, imageWidth, imageHeight)\n",
    "#                 fpinky_k = drawingModule._normalized_to_pixel_coordinates(pinky_k.x, pinky_k.y, imageWidth, imageHeight)\n",
    "                fmidpoint=((findex[0]+fthumb[0])//2, (findex[1]+fthumb[1])//2)\n",
    "                \n",
    "                ######### Circle Finger Tips ################\n",
    "#                 cv2.circle(frame, findex, 15, (0, 255, 0), -1)\n",
    "#                 cv2.circle(frame, fthumb, 15, (0, 255, 0), -1)\n",
    "#                 cv2.circle(frame, fmiddle, 15, (0, 255, 0), -1)\n",
    "#                 cv2.circle(frame, fring, 15, (0, 255, 0), -1)\n",
    "#                 cv2.circle(frame, fpinky, 15, (0, 255, 0), -1)\n",
    "                #############################################\n",
    "                \n",
    "                ######## Measure between index and thumb #############\n",
    "                length = math.hypot(fthumb[0]-findex[0], fthumb[1]-findex[1])\n",
    "                \n",
    "                ########### Measure betwee other fingers #######################\n",
    "                #length2 = math.hypot(findex[0]-fmiddle[0], findex[1]-fmiddle[1]) \n",
    "                #length3 = math.hypot(fmiddle[0]-fring[0], fmiddle[1]-fring[1]) \n",
    "                #length4 = math.hypot(fring[0]-fpinky[0], fring[1]-fpinky[1])\n",
    "                \n",
    "                #cv2.line(frame,findex,fthumb, (255,0,255),3) # draw a line between index and thumb\n",
    "                cv2.circle(frame, fmidpoint, 15, (255, 0, 255), -1) # draw a circle between index and thumb\n",
    "          \n",
    "                \n",
    "                   \n",
    "                # when fingers together then below knuckles remove contours\n",
    "                #if fmiddle[0]>fmiddle_k[0] and length2 <50:\n",
    "                    \n",
    "\n",
    "                #Press c to clear // buttons dont respond propery\n",
    "                if cv2.waitKey(1) == ord('c'):\n",
    "                    points.clear() \n",
    "                    \n",
    "                # pinch index and thumb to draw    \n",
    "                if length < 40:\n",
    "                    points.append(fmidpoint)\n",
    "                \n",
    "                # write \n",
    "                #cv2.putText(frame, \"Prediction is : \" + str(text), (100,100), cv2.FONT_HERSHEY_COMPLEX, 0.7, (255,0,0), 2,cv2.LINE_AA)                                     \n",
    "        \n",
    "        # red contour for frame 1\n",
    "        red_mask = cv2.inRange(frame, red_low, red_high)\n",
    "        red_mask = cv2.dilate(red_mask, None, iterations=1)\n",
    "        red_mask = cv2.erode(red_mask, None, iterations=1)\n",
    "        \n",
    "        cv2.putText(frame, \"Prediction is : \" + str(text), (100,100), cv2.FONT_HERSHEY_COMPLEX, 0.7, (255,0,0), 2,cv2.LINE_AA) \n",
    "               \n",
    "        cv2.imshow(\"window_masked\", red_mask)\n",
    "        cv2.imshow('Test hand', frame)\n",
    "        test_image = image_conversion(red_mask)\n",
    "        text=np.argmax(model.predict(test_image))\n",
    "        ### the buttons need to be spammed till respond\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break # When everything is done, release the capture\n",
    "        #if cv2.waitKey(1) == ord('z'):\n",
    "            \n",
    "        if cv2.waitKey(1) == ord('c'):\n",
    "            points.clear()\n",
    "            text = ''\n",
    "        #elif cv2.waitKey(1) == ord('c'):q\n",
    "            \n",
    "    cv2.destroyAllWindows()\n",
    "    #cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
